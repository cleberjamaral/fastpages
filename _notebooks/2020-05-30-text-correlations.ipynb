{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papers correlations EMAS 2019\n",
    "> Correlation matrix among papers accepted on 7th International Workshop on Engineering Multi-Agent Systems (EMAS 2019)\n",
    "\n",
    "- toc: false\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Cleber Jorge Amaral\n",
    "- categories: [comparison, altair, jupyter]\n",
    "- image: images/text-correlations.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Imports\n",
    "from tika import parser # For parsing PDF and other to TXT\n",
    "import os\n",
    "from os import path, stat\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "import pandas as pd \n",
    "import altair as alt # for charts\n",
    "import re # for searchs in text\n",
    "from bs4 import BeautifulSoup # parse html\n",
    "import requests # http requests\n",
    "from altair_saver import save\n",
    "from scipy import stats, spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Plotting configurations\n",
    "CHART_WIDTH = 600\n",
    "CHART_HEIGHT = 400\n",
    "# Database folder\n",
    "DB_FOLDER = \"../assets/db/\"\n",
    "# File containing the list of papers\n",
    "PAPERS_LIST_FILE = DB_FOLDER + \"EMAS2019_papers_list.txt\"\n",
    "# File containing paper descriptions\n",
    "PAPERS_DESCRIPTION_FILE = DB_FOLDER + \"EMAS2019_papers_description.txt\"\n",
    "# File containing the correlation matrix (for caching)\n",
    "SIMILARITY_FILE = DB_FOLDER + \"EMAS2019_simple_similarity.csv\"\n",
    "CORRELATIONS_FILE = DB_FOLDER + \"EMAS2019_cosine_correlations.csv\"\n",
    "PEARSON_FILE = DB_FOLDER + \"EMAS2019_pearson_similarity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# helpers\n",
    "def parse_document(file):\n",
    "    content = parser.from_file(file)\n",
    "    if 'content' in content:\n",
    "        text = content['content']\n",
    "    else:\n",
    "        return\n",
    "    text = str(text)\n",
    "    # Using utf-8 format\n",
    "    safe_text = text.encode('utf-8', errors='ignore')\n",
    "    # Removing special characters\n",
    "    safe_text = re.sub(\"\\\\\\\\\\\\\\\\x..\", \"\", text)\n",
    "    # Removing returns\n",
    "    safe_text = str(safe_text).replace(\"\\\\\\\\n\", \" \")\n",
    "    # Removing sequences of spaces\n",
    "    safe_text = ' '.join(safe_text.split())\n",
    "    return safe_text\n",
    "    \n",
    "def encode_text(text):\n",
    "        return embed(text)\n",
    "    \n",
    "def create_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder) \n",
    "\n",
    "def save_text(file, text):\n",
    "    text_file = open(file, \"w\")\n",
    "    text_file.write(text)\n",
    "    text_file.close()\n",
    "    \n",
    "def read_text_as_strlist(file):\n",
    "    text_file = open(file, \"r\")\n",
    "    strlist = text_file.read().splitlines() \n",
    "    text_file.close()\n",
    "    return strlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# tensorflow universal-sentence-encoder-multilingual\n",
    "# 16 languages (Arabic, Chinese-simplified, Chinese-traditional, English, French, German, Italian, Japanese, Korean, Dutch, Polish, Portuguese, Spanish, Thai, Turkish, Russian) text encoder.\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "if not os.path.exists(PAPERS_LIST_FILE):\n",
    "    emas_url = 'https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted/'\n",
    "    page_as_text = requests.get(emas_url).text\n",
    "    parsed_html = BeautifulSoup(page_as_text, 'html.parser')\n",
    "    files = [emas_url + '/' + node.get('href') for node in parsed_html.find_all('a') if node.get('href').endswith('pdf')]\n",
    "    create_folder(DB_FOLDER)\n",
    "    save_text(PAPERS_LIST_FILE, '\\n'.join(map(str, files)))\n",
    "else:\n",
    "    files = read_text_as_strlist(PAPERS_LIST_FILE)\n",
    "    descriptions = read_text_as_strlist(PAPERS_DESCRIPTION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-06 06:32:30,414 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_5.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_5.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_5.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_5.pdf.\n",
      "2020-06-06 06:32:34,463 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_8.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_8.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_8.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_8.pdf.\n",
      "2020-06-06 06:32:38,230 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_18.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_18.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_18.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_18.pdf.\n",
      "2020-06-06 06:32:41,500 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_21.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_21.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_21.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_21.pdf.\n",
      "2020-06-06 06:32:44,304 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_22.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_22.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_22.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_22.pdf.\n",
      "2020-06-06 06:32:55,201 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_23.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_23.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_23.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_23.pdf.\n",
      "2020-06-06 06:33:00,307 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_24.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_24.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_24.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_24.pdf.\n",
      "2020-06-06 06:33:05,984 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_25.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_25.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_25.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_25.pdf.\n",
      "2020-06-06 06:33:09,466 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_26.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_26.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_26.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_26.pdf.\n",
      "2020-06-06 06:33:14,604 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_27.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_27.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_27.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_27.pdf.\n",
      "2020-06-06 06:33:21,284 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_28.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_28.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_28.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_28.pdf.\n",
      "2020-06-06 06:33:24,581 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_29.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_29.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_29.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_29.pdf.\n",
      "2020-06-06 06:33:29,086 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_30.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_30.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_30.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_30.pdf.\n",
      "2020-06-06 06:33:33,033 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_31.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_31.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_31.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_31.pdf.\n",
      "2020-06-06 06:33:36,413 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_32.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_32.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_32.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_32.pdf.\n",
      "2020-06-06 06:33:39,973 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_33.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_33.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_33.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_33.pdf.\n",
      "2020-06-06 06:33:45,452 [MainThread  ] [INFO ]  Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_34.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_34.pdf.\n",
      "INFO:tika.tika:Retrieving https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted//EMAS2019_paper_34.pdf to /tmp/lad-emas2019-accepted-emas2019_paper_34.pdf.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "if not os.path.exists(CORRELATIONS_FILE):\n",
    "    \n",
    "    # Create vectors for documents\n",
    "    texts = []\n",
    "    vectors = []\n",
    "    for f in files: \n",
    "        parsed_document = parse_document(f)\n",
    "        texts.append(parsed_document)\n",
    "        vector = encode_text(parsed_document)\n",
    "        vectors.append(vector)\n",
    "        \n",
    "    # Generate papers descriptions file\n",
    "    descriptions = []\n",
    "    for i in range(len(files)):\n",
    "        text = texts[i]\n",
    "        fchar = re.search(r\"[^b'\\\\n]\", text).start()\n",
    "        descriptions.append(text[fchar:fchar+80].replace(\"\\\\n\", \" \").replace(\"\\\\\", \"\"))\n",
    "        save_text(PAPERS_DESCRIPTION_FILE, '\\n'.join(map(str, descriptions)))\n",
    "        \n",
    "    # For plotting, generate a table with the columns paper_a, paper_b, and correlation\n",
    "    file_names = []\n",
    "    for vf in files:\n",
    "        file_name = os.path.basename(vf)\n",
    "        file_names.append(file_name.split('.')[0])\n",
    "        \n",
    "    # https://numpy.org/doc/stable/reference/generated/numpy.inner.html\n",
    "    dfsingle = pd.DataFrame(columns=[\"paper_a\", \"paper_b\", \"correlation\"])\n",
    "    dfsingle.columns = dfsingle.columns.map(str)\n",
    "    \n",
    "    # Process correlations for table with 3 columns\n",
    "    for i in range(len(file_names)):\n",
    "        for j in range(len(file_names)):\n",
    "            # df.values[row, column] = value\n",
    "            dfsingle.loc[(i*len(file_names))+j] = (file_names[i], \n",
    "                                            file_names[j], \n",
    "                                            round(float(np.inner(vectors[i], vectors[j])), 2) * 100)\n",
    "                \n",
    "    # For plotting, generate a table with the columns paper_a, paper_b, and correlation\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "    dfpearson = pd.DataFrame(columns=[\"paper_a\", \"paper_b\", \"correlation\"])\n",
    "    dfpearson.columns = dfpearson.columns.map(str)\n",
    "    \n",
    "    # Process correlations for table with 3 columns\n",
    "    for i in range(len(file_names)):\n",
    "        for j in range(len(file_names)):\n",
    "            # df.values[row, column] = value\n",
    "            dfpearson.loc[(i*len(file_names))+j] = (file_names[i], \n",
    "                                            file_names[j], \n",
    "                                            round(float(stats.pearsonr(vectors[i][0], vectors[j][0])[0]), 2) * 100)\n",
    "\n",
    "    # For plotting, generate a table with the columns paper_a, paper_b, and correlation\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html\n",
    "    dfcosine = pd.DataFrame(columns=[\"paper_a\", \"paper_b\", \"correlation\"])\n",
    "    dfcosine.columns = dfcosine.columns.map(str)\n",
    "    \n",
    "    # Process correlations for table with 3 columns\n",
    "    for i in range(len(file_names)):\n",
    "        for j in range(len(file_names)):\n",
    "            # df.values[row, column] = value\n",
    "            dfcosine.loc[(i*len(file_names))+j] = (file_names[i], \n",
    "                                            file_names[j], \n",
    "                                            round(float(1 - spatial.distance.cosine(vectors[i], vectors[j])), 2) * 100)\n",
    "            \n",
    "    # Save the correlations into a csv file\n",
    "    dfsingle.to_csv(SIMILARITY_FILE)\n",
    "    dfpearson.to_csv(PEARSON_FILE)\n",
    "    dfcosine.to_csv(CORRELATIONS_FILE)\n",
    "else:\n",
    "    dfsingle = pd.read_csv(SIMILARITY_FILE)\n",
    "    dfpearson = pd.read_csv(PEARSON_FILE)\n",
    "    dfcosine = pd.read_csv(CORRELATIONS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "dfplot = pd.DataFrame({'x': dfsingle[\"paper_a\"].ravel(),\n",
    "                   'y': dfsingle[\"paper_b\"].ravel(),\n",
    "                   'Correlation': dfsingle[\"correlation\"].ravel()})\n",
    "\n",
    "chart = alt.Chart(dfplot).mark_rect().encode(\n",
    "    x=alt.X('x:O', axis=alt.Axis(title=\"\")),\n",
    "    y=alt.Y('y:O', axis=alt.Axis(title=\"\")),\n",
    "    color='Correlation:Q'\n",
    ").properties(\n",
    "    title=[\"Inner product (basic similarity function)\"]\n",
    ")\n",
    "\n",
    "text = chart.mark_text(baseline='middle').encode(\n",
    "    text='Correlation:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Correlation >= 70,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    ),\n",
    "    size=alt.value(14),\n",
    "    opacity=alt.value(0.85)\n",
    ")\n",
    "\n",
    "# Draw the chart\n",
    "plot = chart.properties(width=CHART_WIDTH, height=CHART_HEIGHT) + text\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "dfplot = pd.DataFrame({'x': dfcosine[\"paper_a\"].ravel(),\n",
    "                   'y': dfcosine[\"paper_b\"].ravel(),\n",
    "                   'Correlation': dfcosine[\"correlation\"].ravel()})\n",
    "\n",
    "chart = alt.Chart(dfplot).mark_rect().encode(\n",
    "    x=alt.X('x:O', axis=alt.Axis(title=\"\")),\n",
    "    y=alt.Y('y:O', axis=alt.Axis(title=\"\")),\n",
    "    color='Correlation:Q'\n",
    ").properties(\n",
    "    title=[\"Cosine similarity\"]\n",
    ")\n",
    "\n",
    "text = chart.mark_text(baseline='middle').encode(\n",
    "    text='Correlation:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Correlation >= 70,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    ),\n",
    "    size=alt.value(14),\n",
    "    opacity=alt.value(0.85)\n",
    ")\n",
    "\n",
    "# Draw the chart\n",
    "plot = chart.properties(width=CHART_WIDTH, height=CHART_HEIGHT) + text\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "dfplot = pd.DataFrame({'x': dfpearson[\"paper_a\"].ravel(),\n",
    "                   'y': dfpearson[\"paper_b\"].ravel(),\n",
    "                   'Correlation': dfpearson[\"correlation\"].ravel()})\n",
    "\n",
    "chart = alt.Chart(dfplot).mark_rect().encode(\n",
    "    x=alt.X('x:O', axis=alt.Axis(title=\"\")),\n",
    "    y=alt.Y('y:O', axis=alt.Axis(title=\"\")),\n",
    "    color='Correlation:Q'\n",
    ").properties(\n",
    "    title=[\"Pearson correlation\"]\n",
    ")\n",
    "\n",
    "text = chart.mark_text(baseline='middle').encode(\n",
    "    text='Correlation:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Correlation >= 70,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    ),\n",
    "    size=alt.value(14),\n",
    "    opacity=alt.value(0.85)\n",
    ")\n",
    "\n",
    "# Draw the chart\n",
    "plot = chart.properties(width=CHART_WIDTH, height=CHART_HEIGHT) + text\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "for i in range(len(files)):\n",
    "    print(os.path.basename(files[i]), \": \", descriptions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works?\n",
    "It downloads the accepted papers available in [EMAS 2019](https://cgi.csc.liv.ac.uk/~lad/emas2019/accepted/) page. Each paper in PDF is converted to a plain text using [Apache Tika](https://tika.apache.org/). Then using [Google Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder-multilingual/3) they are [vectorized](https://ai.googleblog.com/2019/07/multilingual-universal-sentence-encoder.html). These vectors are compared creating correlations. The correlations vary from 0 to 100% of similarity. Those values are presented in an [Altair correlation matrix](https://altair-viz.github.io/gallery/simple_heatmap.html).\n",
    "### What else it can do?\n",
    "I use it to find correlations across many papers and books I use in my researches. Since I use [Mendeley](https://www.mendeley.com/), all of them are in a plain folder. The project called [text-correlation](https://github.com/cleberjamaral/text-correlation) retrieves all documents from a local folder creating a correlation matrix `n x n` in a `.csv` file. It is better for larger number of documents and suitable to open in a spreadsheet processor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "Developed by [Cleber Jorge Amaral](https://cleberjamaral.github.io/), acknowledging it is highly inspired by a work presented by Aladdin Shamoug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "save(plot,\"../images/text-correlations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
